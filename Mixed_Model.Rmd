---
title: "Mixed Model"
author: "Jake Smith"
---

Expand the model fit in Multichannel_CNN_Model to include a branch for waveform descriptors.

```{r setup, include=FALSE}
# import required libraries
require(keras)
require(dplyr)
```

Load the list of songs. Using the identical 80/20/20 train/validation/test split from Simple_CNN_Model.

```{r}
## train/test split
# import the metadata information
music <- data.table::fread("./selected_music.csv")

# convert genres to factor
music <- music %>% mutate(Genre = as.factor(Genre))

# count number of songs per genre and number of genres
songs.per.genre <- music %>% group_by(Genre) %>% count()
genre.count <- dim(songs.per.genre)[1]
songs.per.genre <- songs.per.genre$n[1]

# set seed for reproducible train/test split
set.seed(998)

# using an 60/20/20 train/validation/test split stratified by genre
# divide out 20% of the dataset for the test set
music.test <- music %>% group_by(Genre) %>% sample_n(0.2 * songs.per.genre) %>% ungroup()
music.train <- setdiff(music, music.test)

# divide out an additional 20% of the dataset for the validation set
music.validation <- music.train %>% group_by(Genre) %>% sample_n(0.2 * songs.per.genre) %>% ungroup()
music.train <- setdiff(music.train, music.validation)
```

Load the dataset of waveform descriptors.

```{r}
# load the descriptors
music.descriptors <- data.table::fread("reproduction/music_descriptors.csv", data.table = FALSE)

# count number of songs per genre and number of genres
songs.per.genre <- music.descriptors %>% group_by(genre) %>% count()
genre.count <- dim(songs.per.genre)[1]
songs.per.genre <- songs.per.genre$n[1]
```

Format and transform waveform descriptors as was done in the past.

```{r}
# function to format/transform the data; taken from previous work
# takes a dataframe x.df
format.as.train <- function (x.df) {
  # generate a list of the parent names for the time-series features
  features <- unique(sub(pattern = "\\..*", replacement = "", grep("\\..*", colnames(x.df), value = TRUE)))

  # reorder the features such that *.1 through *.10 are in order
  x.reordered <- x.df[, c("genre", "song", "length", outer(1:10, features, function(x, y) {paste(y, x, sep = ".")}))]
  
  # for each pair of time-series features n and n+1, compute |n+1 - n|
  for (i in 1:length(features)) {
    for (j in 1:9)
      x.reordered[, paste(features[i], "dif", j, sep = ".")] <- 
        abs(x.reordered[, paste(features[i], j+1, sep = ".")] - x.reordered[, paste(features[i], j, sep = ".")])
  }
  
  # log/root transform features with significant right skew
  x.reordered <- mutate_at(x.reordered, vars(one_of(c("length", 
           outer(c("kurtosis", "Q25", "roughness", "skewness", "zcr"), 1:10, paste, sep = ".")))), 
           function(x) {log(x + .0001)})
  x.reordered <- mutate_at(x.reordered, vars(one_of(c("length", 
           outer(c("amplitude.dif", "centroid.dif", "entropy.dif", "kurtosis.dif", "Q25.dif", "Q75.dif", "skewness.dif", "zcr.dif"), 1:9, paste, sep = ".")))), 
           function(x) {(x^(1/4))})
  x.reordered <- mutate_at(x.reordered, vars(one_of(c("length", 
           outer("flatness.dif", 1:9, paste, sep = ".")))), 
           function(x) {(x^(1/2))})
  x.reordered <- mutate_at(x.reordered, vars(one_of(c("length", 
           outer("roughness.dif", 1:9, paste, sep = ".")))), 
           function(x) {(x^(1/10))})
  
  # power transform features with significant left skew
  x.reordered <- mutate_at(x.reordered, vars(one_of(
           outer(c("entropy"), 1:10, paste, sep = "."))), 
           function(x) {x^(20)})
  x.reordered <- mutate_at(x.reordered, vars(one_of(
           outer(c("flatness"), 1:10, paste, sep = "."))), 
           function(x) {x^(4)})
  x.reordered <- mutate_at(x.reordered, vars(one_of(
           outer(c("Q75"), 1:10, paste, sep = "."))), 
           function(x) {x^(3)})
  
  # scale all numeric features to N(0, 1) distribution
  # rebuild dataframe with scaled columns
  x.reordered <- cbind(select(x.reordered, song, genre), sapply(select(x.reordered, -song, - genre), scale))
  
  # return the transformed/formatted dataframe
  return(x.reordered)
}

# call the function
music.descriptors <- format.as.train(music.descriptors)
```

Modify the data generator function from Simple_CNN_Model to additionally return the waveform descriptors data for the current batch.

```{r}
## data generator function
# data.indices: a vector of indices to draw batches from
# batch.size: the number of observations to return per batch
# subset: an integer number of timepoints down which to truncate each sample
#         each timepoint corresponds to approximately 10 ms
#         the starting timepoint for the samples is selected at random for each batch
#         when subset = 0 (default), the entire sample is used
# na.rm: boolean flag (default TRUE), when true checks for missing values and removes those observations
# returns batches of data divided into feature matrix X, second feature matrix X.descriptors, and target matrix Y
data.generator <- function(data.indices, batch.size, subset = 0, na.rm = TRUE) {
  # initiate a counter for batches
  batch <- 0
  max.batches <- ceiling(length(data.indices) / batch.size)
  
  # shuffle data.indices
  data.indices <- sample(data.indices)
  
  # initiate a function to sample the data
  function() {

    # update the batch counter
    batch <<- batch + 1

    # reset missing observations
    missing.obs <- c()
        
    # cycle through batches
    if (batch < max.batches) {
      # take batch.size observations
      batch.start <- (batch - 1) * batch.size + 1
      batch.end  <- batch * batch.size
      
    } else if (batch == max.batches) {
      # take as many additional observations as possible
      batch.start <- (batch - 1) * batch.size + 1
      batch.end <- length(data.indices)

      # reset the batch counter 
      batch <<- 0
      
      # reshuffle data indices
      data.indices <<- sample(data.indices)
    }
    
    ## generate feature matrix X
    # load MFCC descriptors for each song in the batch
    X <- sapply(data.indices[batch.start:batch.end], function(x) {get(load(paste("./data/", x, ".descriptors", sep = "")))}, simplify = "array")
    
    # reorder array into observation > timepoint > octave > region
    X <- aperm(X, c(4, 1, 2, 3))
    
    # if requested and necessary, truncate X
    if (subset > 0 && subset != dim(X)[2]) {
      # cut sample down to subset datapoints
      z <- sample(1:(dim(X)[2] - subset), 1)
      X <- X[, z:(z + subset - 1), , ]
    }
    
    # if requested, remove observations with missing values
    if (na.rm == TRUE) {
      # identify observations with missing values
      missing.obs <- unique(which(is.na(X) == TRUE, arr.ind = TRUE)[, 1])
      
      # remove those observations from X if necessary
      if (length(missing.obs) > 0) {
        X <- X[-missing.obs, , , ]
      }
    }
    
    # scale descriptors to [-1, 1] on an individual song level
    X <- apply(X, c(2, 3, 4), function(x) {x / max(abs(x), na.rm = TRUE)})
    
    ## generate feature matrix X.descriptors
    X.descriptors <- music.descriptors[data.indices[batch.start:batch.end], ] %>% select(-genre, -song) %>% as.matrix()
    
    # if requested and necessary, remove missing observations from Y
    if (na.rm == TRUE && length(missing.obs) > 0) {
      X.descriptors <- X.descriptors[-missing.obs, ]
    }

    ## generate one-hot encoded target matrix Y
    Y <- sapply(data.indices[batch.start:batch.end], function(x) {music$Genre[music$Index == x]})
    Y <- Y %>% as.numeric() %>% (function(x) {x - 1}) %>% to_categorical(num_classes = genre.count)
    
    # if requested and necessary, remove missing observations from Y
    if (na.rm == TRUE && length(missing.obs) > 0) {
      Y <- Y[-missing.obs, ]
    }
    
    ## return the current batch
    return(list(list(X, X.descriptors), Y))
  }
}
```

We will add a second fully-connected branch to the model fit in Multichannel_CNN_Model to process the waveform descriptors then concatenate it with the MFCC branch.

-- MFCC branch --
input
slice on region

-- in triplicate --
add dummy region

2D convolution
2D max pool
2D convolution
2D max pool

flatten
-- end triplicate --
-- end MFCC branch --

-- waveform branch --
dense
dropout
dense
dropoout
-- end waveform branch --

concatenate
dense
dropout
output


```{r}
## define the model
# L2 regularization weighting parameter
reg_lambda = 0.01
# number of datapoints to include per channel per song per epoch
sample_length = 300

## MFCC layers
# MFCC input layer
input_layer_mfcc <- layer_input(shape = c(sample_length, 64, 3), name = "input_layer_mfcc")


# initialize a list to hold the regional layers
regional_layers <- list()

# construct regional layers
for (i in 1:3) {
  regional_layers[[i]] <- input_layer_mfcc %>%
  # lambda function layer to select the region
  layer_lambda(function(x) x[, , , 1]) %>%
  # lambda function to add a dummy channels dimension (1)
  layer_lambda(function(x) k_expand_dims(x, 4)) %>%
  # convolution layer 1
  layer_conv_2d(
    filters = 64, 
    kernel_size = c(3, 3), 
    strides = c(1, 1), 
    activation = "relu", 
    kernel_regularizer = regularizer_l2(reg_lambda)
  ) %>%
  # max pooling layer 1
  layer_max_pooling_2d(pool_size = c(4, 2)) %>%
  # convoution layer 2
  layer_conv_2d(
    filters = 64, 
    kernel_size = c(5, 3), 
    strides = c(1, 1), 
    activation = "relu",
    kernel_regularizer = regularizer_l2(reg_lambda)
  ) %>%
  # max pooling layer 2
  layer_max_pooling_2d(pool_size = c(4, 2)) %>%
  # flatten layer
  layer_flatten()
}

## waveform branch
# waveform input layer
input_layer_waveform <- layer_input(shape = c(191), name = "input_layer_waveform")

waveform_layers <- input_layer_waveform %>%
# fully connected layer 1
layer_dense(
  units = 64,
  activation = "relu",
  kernel_regularizer = regularizer_l2(reg_lambda)
) %>%
# dropout layer 1
layer_dropout(rate = 0.5) %>%
# fully connected layer 2
layer_dense(
  units = 64,
  activation = "relu",
  kernel_regularizer = regularizer_l2(reg_lambda)
) %>%
# dropout layer 2
layer_dropout(rate = 0.5)

# build output layer from three regional layers and waveform layer
# concatenate flattened regional layers
output_layers <- c(regional_layers, waveform_layers) %>% layer_concatenate() %>%
# fully connected layer 1
layer_dense(
  units = 128,
  activation = "relu", 
  kernel_regularizer = regularizer_l2(reg_lambda)
) %>%
# dropout layer
layer_dropout(rate = 0.2) %>%
# output layer
layer_dense(genre.count, activation = "softmax")


# combine input and output layers into a model
model <- keras_model(inputs = c(input_layer_mfcc, input_layer_waveform), outputs = output_layers)

# compile the model
compile(model, 
        loss = "categorical_crossentropy", 
        optimizer = optimizer_adam(decay = 1e-9), 
        metrics = "accuracy"
)
```

```{r}
## fit the model
batch.size = 64
epochs = 10
starting.epoch = 0


# fit the model
fit_generator(
  model, 
  data.generator(music.train$Index, batch.size, sample_length),
  steps_per_epoch = ceiling(length(music.train$Index) / batch.size),
  epochs = epochs,
  validation_data = data.generator(music.validation$Index, batch.size, sample_length), 
  validation_steps = ceiling(length(music.validation$Index) / batch.size),
  initial_epoch = starting.epoch
)
```

