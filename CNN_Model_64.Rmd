---
title: "CNN_Model_64"
author: "Jake Smith"
date: "8/11/2019"
---

```{r setup, include=FALSE}
require(keras)
require(dplyr)
```

```{r}
## train/test split
# import the metadata information
music <- data.table::fread("./selected_music.csv")

# convert genres to factor
music <- music %>% mutate(Genre = as.factor(Genre))

# count number of songs per genre and number of genres
songs.per.genre <- music %>% group_by(Genre) %>% count()
genre.count <- dim(songs.per.genre)[1]
songs.per.genre <- songs.per.genre$n[1]

# set seed for reproducible train/test split
set.seed(998)

# using an 60/20/20 train/validation/test split stratified by genre
# divide out 20% of the dataset for the test set
music.test <- music %>% group_by(Genre) %>% sample_n(0.2 * songs.per.genre) %>% ungroup()
music.train <- setdiff(music, music.test)

# divide out an additional 20% of the dataset for the validation set
music.validation <- music.train %>% group_by(Genre) %>% sample_n(0.2 * songs.per.genre) %>% ungroup()
music.train <- setdiff(music.train, music.validation)
```

```{r}
## data generator function
# data.indices: a vector of indices to draw batches from
# batch.size: the number of observations to return per batch
data.generator <- function(data.indices, batch.size) {
  # initiate a counter for batches
  batch <- 0
  max.batches <- ceiling(length(data.indices) / batch.size)
  
  # shuffle data.indices
  data.indices <- sample(data.indices)
  
  # initiate a function to sample the data
  function() {
  
    # update the batch counter
    batch <<- batch + 1
    
    # cycle through batches
    if (batch < max.batches) {
      # take batch.size observations
      batch.start <- (batch - 1) * batch.size + 1
      batch.end  <- batch * batch.size
      
    } else if (batch == max.batches) {
      # take as many additional observations as possible
      batch.start <- (batch - 1) * batch.size + 1
      batch.end <- length(data.indices)

      # reset the batch counter 
      batch <<- 0
    }
    
    # generate feature matrix X
    # load MFCC descriptors for each song in the batch
    X <- sapply(data.indices[batch.start:batch.end], function(x) {get(load(paste("./data/", x, ".descriptors", sep = "")))}, simplify = "array")
    
    # reorder array into observation > timepoint > octave > region
    X <- aperm(X, c(4, 1, 2, 3))
    
    # scale descriptors to [-1, 1] on an individual song level
    X <- apply(X, c(2, 3, 4), function(x) {x / max(abs(x), na.rm = TRUE)})
    
    # randomly select a 3s segment of X
    z <- sample(1:(dim(X)[2] - 99), 1)
    X <- X[, z:(z+99), , ]
    
    # generate one-hot encoded target matrix Y
    Y <- sapply(data.indices[batch.start:batch.end], function(x) {music$Genre[music$Index == x]})
    Y <- Y %>% as.numeric() %>% (function(x) {x - 1}) %>% to_categorical(num_classes = genre.count)
    
    # return the current batch
    return(list(X, Y))
  }
}
```


```{r}
## define the model
batch.size = 50
epochs = 50
reg_lambda = 0.01

# define the model
model <- keras_model_sequential()
model %>%
  # lambda function layer to select the first region
  layer_lambda(function(x) x[, , , 1], input_shape = c(100, 64, 3)) %>%
  # lambda function to add a dummy channels dimension (1)
  layer_lambda(function(x) k_expand_dims(x, 4)) %>%
  # convolution layer 1
  layer_conv_2d(
    filters = 64, 
    kernel_size = c(3, 3), 
    strides = c(1, 1), 
    activation = "relu", 
    kernel_regularizer = regularizer_l2(reg_lambda)
  ) %>%
  # max pooling layer 1
  layer_max_pooling_2d(pool_size = c(4, 2)) %>%
  # convoution layer 2
  layer_conv_2d(
    filters = 64, 
    kernel_size = c(5, 3), 
    strides = c(1, 1), 
    activation = "relu",
    kernel_regularizer = regularizer_l2(reg_lambda)
  ) %>%
  # max pooling layer 2
  layer_max_pooling_2d(pool_size = c(4, 2)) %>%
  # flatten layer
  layer_flatten() %>%
  # fully connected layer 1
  layer_dense(
    units = 32, 
    activation = "relu",
    kernel_regularizer = regularizer_l2(reg_lambda)
  ) %>%
  # dropout layer
  layer_dropout(rate = 0.2) %>%
  # output layer
  layer_dense(genre.count, activation = "softmax")
```


```{r}
## fit the model
# compile the model
compile(model, 
        loss = "categorical_crossentropy", 
        optimizer = optimizer_adadelta(decay = 1e-5), 
        metrics = "accuracy"
)

# fit the model
fit_generator(
  model, 
  data.generator(music.train$Index, batch.size), 
  steps_per_epoch = ceiling(length(music.train$Index) / batch.size), 
  epochs = epochs, 
  validation_data = data.generator(music.validation$Index, batch.size), 
  validation_steps = ceiling(length(music.validation$Index) / batch.size),
  initial_epoch = 1
)
```

